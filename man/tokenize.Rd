% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenize}
\alias{tokenize_tbl}
\alias{tokenize_tidytext}
\alias{tokenize_tidy}
\title{Simple version of tokenizer function.}
\usage{
tokenize(
  text,
  match_option = Match$ALL,
  stopwords = TRUE,
  blocklist = NULL,
  pretokenized = NULL,
  normalize_coda = FALSE,
  typos = NULL,
  typo_cost_threshold = 2.5,
  open_ending = FALSE,
  allowed_dialects = Dialect$STANDARD,
  dialect_cost = 3
)

tokenize_tbl(
  text,
  match_option = Match$ALL,
  stopwords = TRUE,
  blocklist = NULL,
  pretokenized = NULL,
  normalize_coda = FALSE,
  typos = NULL,
  typo_cost_threshold = 2.5,
  open_ending = FALSE,
  allowed_dialects = Dialect$STANDARD,
  dialect_cost = 3
)

tokenize_tidytext(
  text,
  match_option = Match$ALL,
  stopwords = TRUE,
  blocklist = NULL,
  pretokenized = NULL,
  normalize_coda = FALSE,
  typos = NULL,
  typo_cost_threshold = 2.5,
  open_ending = FALSE,
  allowed_dialects = Dialect$STANDARD,
  dialect_cost = 3
)

tokenize_tidy(
  text,
  match_option = Match$ALL,
  stopwords = TRUE,
  blocklist = NULL,
  pretokenized = NULL,
  normalize_coda = FALSE,
  typos = NULL,
  typo_cost_threshold = 2.5,
  open_ending = FALSE,
  allowed_dialects = Dialect$STANDARD,
  dialect_cost = 3
)
}
\arguments{
\item{text}{target text.}

\item{match_option}{\code{\link{Match}}: use Match. Default is Match$ALL}

\item{stopwords}{stopwords option. Default is TRUE which is
to use embaded stopwords dictionany.
If FALSE, use not embaded stopwords dictionany.
If char: path of dictionary txt file, use file.
If \code{\link{Stopwords}} class, use it.
If not valid value, work same as FALSE.
Check \code{\link[=analyze]{analyze()}} how to use stopwords param.}

\item{blocklist}{\code{Morphset(optional)}: morpheme set to block from analysis results. Default is NULL.}

\item{pretokenized}{\code{Pretokenized(optional)}: pretokenized object for guided analysis. Default is NULL.}

\item{normalize_coda}{\code{bool(optional)}: apply coda normalization. Default is FALSE.}

\item{typos}{\code{bool(optional)}: enable typo correction. Default is NULL (keep current).}

\item{typo_cost_threshold}{\code{num(optional)}: typo correction cost threshold. Default is 2.5.}

\item{open_ending}{\code{bool(optional)}: keep sentence open after last morpheme. Default is FALSE.}

\item{allowed_dialects}{\code{Dialect(optional)}: allowed dialects for analysis. Default is Dialect$STANDARD.}

\item{dialect_cost}{\code{num(optional)}: cost added to dialect morphemes. Default is 3.0.}
}
\value{
list type of result.
}
\description{
Simple version of tokenizer function.
}
\examples{
\dontrun{
  tokenize("Test text.")
  tokenize("Please use Korean.", Match$ALL_WITH_NORMALIZING)

  # New features with Kiwi v0.21.0
  kw <- Kiwi$new()
  morphset <- kw$create_morphset()
  tokenize("Test text.", blocklist = morphset)
}
}
