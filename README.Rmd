---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
options(crayon.enabled = NULL)
```

# elbird [<img src="man/figures/logo.png" align="right" height=140/>](https://mrchypark.github.io/elbird/index.html)

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![R-CMD-check](https://github.com/mrchypark/elbird/workflows/R-CMD-check/badge.svg)](https://github.com/mrchypark/elbird/actions)
[![CRAN status](https://www.r-pkg.org/badges/version/elbird)](https://cran.r-project.org/package=elbird)
[![runiverse-name](https://mrchypark.r-universe.dev/badges/:name)](https://mrchypark.r-universe.dev/)
[![runiverse-package](https://mrchypark.r-universe.dev/badges/elbird)](https://mrchypark.r-universe.dev/ui#packages)
[![metacran downloads](https://cranlogs.r-pkg.org/badges/elbird)](https://cran.r-project.org/package=elbird)
[![Downloads](https://cranlogs.r-pkg.org/badges/grand-total/elbird)](https://cran.r-project.org/package=elbird)
[![Codecov test coverage](https://codecov.io/gh/mrchypark/elbird/branch/main/graph/badge.svg)](https://app.codecov.io/gh/mrchypark/elbird?branch=main)
<!-- badges: end -->

* [Korean version README](https://mrchypark.github.io/elbird/articles/README_kr.html)

The `elbird` package is a morpheme analyzer packed with [Kiwi](https://github.com/bab2min/Kiwi).
It is based on cpp package `Kiwi` and that has convenient functions such as faster performance compared to other tokenizers, easy user dictionary addition, unregistered noun extraction, etc.

### logo

<a href="https://www.flaticon.com/free-icons/wings" title="wings icons">Wings icons created by Good Ware - Flaticon</a>    
<a href="https://www.flaticon.com/free-icons/africa" title="africa icons">Africa icons created by Eucalyp - Flaticon</a>

## Installation

You can install the elbird with:

```r
# CRAN
install.packages("elbird")

# Dev version
install.packages('elbird', repos = c('https://mrchypark.r-universe.dev', 'https://cloud.r-project.org'))
```

## Example

The examples below introduce the behavior of `elbird`'s functions.

### tokenize

Basically, the `tokenize` function return list form and the `tokenize_tbl` organized in tibble data type, and grammar compatibility with tidytext are supported provides an `tokenize_tidy` function.

```{r}
library(elbird)
tokenize("안녕하세요 kiwi 형태소 분석기의 R wrapper인 elbird를 소개합니다.")
tokenize_tidy("안녕하세요 kiwi 형태소 분석기의 R wrapper인 elbird를 소개합니다.")
```

Multiple sentences are input as `vector` or `list` and output as `list`.

```{r}
tokenize(c("새롭게 작성된 패키지 입니다.", "tidytext와의 호환을 염두하고 작성하였습니다."))
tokenize_tidy(c("새롭게 작성된 패키지 입니다.", "tidytext와의 호환을 염두하고 작성하였습니다."))
```

### With tidytext

The `tokenize_tidy` function can also be used as `tokenize_tt` and `tokenize_tidytext`.
Below is an example of using it with the `tidytext` package.
The `tar` below is the target text for morpheme analysis.

```{r}
suppressMessages(library(dplyr))
# install.packages("komment", repos = "https://forkonlp.r-universe.dev/")
library(stringr)
library(tidytext)
library(komment)

speech_list %>% 
  filter(president == "이명박") %>% 
  filter(str_detect(title, "취임사")) %>% 
  pull(link) %>% 
  get_speech(paragraph = T) %>%
  select(paragraph, content) -> tar
tar
```

This is an example of using `tokenize_tidy` of `elbird` as a tokenizer with `tar` as `unnest_tokens` which is a function of `tidytext` package.

```{r}
tar %>% 
  unnest_tokens(
    input = content,
    output = word,
    token = tokenize_tidy
    )
```

```{r}
library(ggplot2)
tar %>% 
  unnest_tokens(
    input = content,
    output = word,
    token = tokenize_tidy
    ) %>%
  count(word) %>%
  top_n(10) %>%
  ggplot(aes(n, word)) +
  geom_col(show.legend = FALSE)
```


### analyze

In addition, an `analyze` function is provided that uses the output of multi-result with there score.

```{r}
library(elbird)
analyze("안녕하세요 kiwi 형태소 분석기의 R wrapper인 elbird를 소개합니다.")
analyze(c("안녕하세요. kiwi 형태소 분석기의 R wrapper인 elbird를 소개합니다."), top_n = 1)
```

## New Features in v0.3.0 (Kiwi v0.21.0)

elbird v0.3.0 introduces several powerful new features based on the upgraded Kiwi v0.21.0 library:

### Advanced Analysis with Morphset and Pretokenized Objects

The new version supports advanced morphological analysis with morpheme blocking and guided tokenization:

```{r}
# Create a Kiwi instance
kw <- Kiwi$new()

# Create a morphset to block specific morphemes
morphset <- kw$create_morphset()
morphset$add("안녕", "IC")  # Block interjection "안녕"

# Analyze with morpheme blocking
result_with_blocklist <- kw$analyze("안녕하세요 여러분", blocklist = morphset)
result_without_blocklist <- kw$analyze("안녕하세요 여러분")

# Compare results
cat("Without blocklist:\n")
print(result_without_blocklist[[1]][[1]]$Token)
cat("\nWith blocklist (blocking '안녕'):\n")
print(result_with_blocklist[[1]][[1]]$Token)
```

### Typo Correction

Enable automatic typo correction for more robust text analysis:

```{r}
# Enable typo correction with default settings
kw$set_typo_correction(TRUE)

# Analyze text with intentional typos
result_with_typo <- kw$analyze("안뇽하세요 여러뷴")  # "안녕하세요 여러분" with typos
print(result_with_typo[[1]][[1]]$Token)

# Add custom typo correction rules
custom_rules <- list(
  list(orig = "안녕", error = "안뇽", cost = 1.0),
  list(orig = "여러분", error = "여러뷴", cost = 1.5)
)
kw$set_typo_correction(TRUE, cost_threshold = 2.0, custom_typos = custom_rules)
```

### Pretokenized Analysis

Guide the analysis process with predefined token boundaries:

```{r}
# Create a pretokenized object
pt <- kw$create_pretokenized()

# Add a span and tokens
span_id <- pt$add_span(0, 15)  # Span for "안녕하세요 여러분"
pt$add_token_to_span(span_id, "안녕하세요", "IC", 0, 5)
pt$add_token_to_span(span_id, "여러분", "NP", 6, 9)

# Analyze with pretokenized guidance
result_pretokenized <- kw$analyze("안녕하세요 여러분", pretokenized = pt)
print(result_pretokenized[[1]][[1]]$Token)
```

### Enhanced Simple Functions

The simple `analyze()` and `tokenize()` functions now support the new features:

```{r}
# Use morphset with simple functions
morphset <- kw$create_morphset()
morphset$add("하세요", "EP")

# Simple analyze with blocklist
result <- analyze("안녕하세요 여러분", blocklist = morphset)
print(result[[1]][[1]]$Token)

# Simple tokenize with blocklist
tokens <- tokenize("안녕하세요 여러분", blocklist = morphset)
print(tokens)
```

## Migration Guide

### For Existing Users

All existing code will continue to work without any changes. The new parameters (`blocklist`, `pretokenized`) are optional and default to `NULL`.

```{r eval=FALSE}
# Existing code works unchanged
result <- analyze("텍스트 분석")
tokens <- tokenize("텍스트 분석")
kw <- Kiwi$new()
kw_result <- kw$analyze("텍스트 분석")
```

### To Use New Features

1. **Morpheme Blocking**: Create a morphset and add morphemes to block
2. **Typo Correction**: Enable with `set_typo_correction()` method
3. **Pretokenized Analysis**: Create pretokenized objects with predefined spans and tokens

### System Requirements

- **C++17 compatible compiler** (upgraded from C++11)
- All other requirements remain the same

## tag set

[Tag list](https://github.com/bab2min/kiwipiepy#%ED%92%88%EC%82%AC-%ED%83%9C%EA%B7%B8) that used in [kiwipiepy](https://github.com/bab2min/kiwipiepy) package.

```{r echo=FALSE, results='asis'}
cat(paste0("* The table below is fetched at ", Sys.time()," ",Sys.timezone(),"."))
```

```{r echo=FALSE}
httr::GET("https://github.com/bab2min/kiwipiepy/blob/master/README.md") %>% 
  httr::content() %>% 
  rvest::html_table() %>% 
  knitr::kable(format = "markdown")
```

## Special Thanks to

### kiwi package
[bab2min](https://github.com/bab2min) with [kiwi package](https://github.com/bab2min/Kiwi) author.

### logo
[jhk0530](https://github.com/jhk0530) with [suggestion](https://github.com/mrchypark/elbird/issues/6).

### cpp backend
[kkweon](https://github.com/kkweon) with [kiwigo package](https://github.com/codingpot/kiwigo)
